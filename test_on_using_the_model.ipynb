{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa2c504a-c48d-4099-bb0c-d3003563a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import maketab as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd499e56-c7b5-492d-8513-836dde5fbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train_data):\n",
    "    mins = np.min(train_data, axis=1, keepdims=True)\n",
    "    maxs = np.max(train_data, axis=1, keepdims=True)\n",
    "    normalized_train = (train_data - mins) / (maxs - mins)\n",
    "    params = {'mins': mins, 'maxs': maxs}   \n",
    "    return normalized_train, params\n",
    "\n",
    "def denormalize(normalized_train, params):\n",
    "    mins = params['mins']\n",
    "    maxs = params['maxs']\n",
    "    denormalized_train = normalized_train * (maxs - mins) + mins    \n",
    "    return denormalized_train\n",
    "\n",
    "def norm(data):\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dee8ccc-4d98-4e59-80b0-4638d9ee9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP class (must match the original definition)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input to hidden layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)  # Hidden to output layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)  # Pass through the hidden layer\n",
    "        #out = self.relu(out)  # Apply ReLU activation\n",
    "        out = self.tanh(out)\n",
    "        out = self.fc2(out)  # Pass through the output layer\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6832034b-6454-432f-aad0-a15e360cfbf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load('bat_model.pth')\n",
    "\n",
    "# Extract architecture parameters\n",
    "seq_length = checkpoint['seq_length']\n",
    "num_layers = checkpoint['num_layers']\n",
    "starting_point = checkpoint['starting_point']\n",
    "input_size = checkpoint['input_size']\n",
    "hidden_size = checkpoint['hidden_size']\n",
    "output_size = checkpoint['output_size']\n",
    "\n",
    "# Instantiate the model\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "# Load the state dictionary\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4defca4d-a22c-4c32-b6be-d5bbf9f7c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_data = data[0]\n",
    "        output_data = data[1]\n",
    "        time_data = data[2]\n",
    "        #time_data = t = np.linspace(0, 1, len(data[1]))\n",
    "        for i in range(starting_point, len(input_data) - seq_length, seq_length):\n",
    "            x = input_data[i:i + seq_length]\n",
    "            #t = time_data[i:i + seq_length]\n",
    "            t = norm(np.arange(0, seq_length)*100)\n",
    "            y = output_data[i:i + seq_length]\n",
    "            #print(f\"x data: {x}\")\n",
    "            #print(f\"t data: {t}\")\n",
    "\n",
    "            slope2, slope, intercept = np.polyfit(t, x, 2)\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            #slope = slope*10**(5)\n",
    "            #slope2 = slope2*10**(8)\n",
    "            #std = std*10**(1)\n",
    "            X = torch.tensor((slope2, slope, intercept, mean, std), dtype=torch.float32)\n",
    "            #print(f\"X = {X}\")\n",
    "            pred = model(X).numpy()\n",
    "            #reg = 10**(-8)*pred[0]*t**2 + 10**(-5)*pred[1]*t + pred[2] #Unscaling the numbers back\n",
    "            reg = pred[0]*t**2 + pred[1]*t + pred[2] #Unscaling the numbers back\n",
    "            print(f\"result: {reg[0]}\")\n",
    "            \n",
    "            plt.plot(t, x, c='blue', label=\"baterie[V]\")\n",
    "            plt.plot(t, y, c='red', label=\"realna odhadovana kapacita[%]\")\n",
    "            plt.plot(t, reg, c='green', label=\"predikovana kapacita [%]\")\n",
    "            if (i <= starting_point): #otherwise it will print more than once\n",
    "                plt.legend()\n",
    "            plt.errorbar(t[0], pred[3], pred[4], linestyle='None')\n",
    "            #plt.scatter(t[0], pred[3], color=\"black\", linewidth=1)\n",
    "            plt.close()\n",
    "\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d650eb5-170e-4ffe-b889-ea69691abf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416000\n",
      "Evaluating on test data...\n",
      "result: 0.998792827129364\n",
      "result: 0.9988324046134949\n",
      "result: 0.9988683462142944\n",
      "result: 0.9988758563995361\n",
      "result: 0.9989136457443237\n",
      "result: 0.9990628361701965\n",
      "result: 0.9989644289016724\n",
      "result: 0.9989694952964783\n",
      "result: 0.998979926109314\n",
      "result: 0.9989929795265198\n",
      "result: 0.9990207552909851\n",
      "result: 0.9990248680114746\n",
      "result: 0.9990609288215637\n",
      "result: 0.9990846514701843\n",
      "result: 0.9990600943565369\n",
      "result: 0.9990813732147217\n",
      "result: 0.9990796446800232\n",
      "result: 0.9990941286087036\n",
      "result: 0.9991018772125244\n",
      "result: 0.9991390705108643\n",
      "result: 0.9991329312324524\n",
      "result: 0.9991433620452881\n",
      "result: 0.9991510510444641\n",
      "result: 0.9991786479949951\n",
      "result: 0.9991710782051086\n",
      "result: 0.9991804957389832\n",
      "result: 0.9991698265075684\n",
      "result: 0.9992177486419678\n",
      "result: 0.9992771744728088\n",
      "result: 0.9992607235908508\n",
      "result: 0.9992530345916748\n",
      "result: 0.9992236495018005\n",
      "result: 0.9992183446884155\n",
      "result: 0.9992282390594482\n",
      "result: 0.9992433786392212\n",
      "result: 0.9992470145225525\n",
      "result: 0.9992528557777405\n",
      "result: 0.999275803565979\n",
      "result: 0.9992762804031372\n",
      "result: 0.9992801547050476\n",
      "result: 0.9993195533752441\n",
      "result: 0.9993122220039368\n",
      "result: 0.9992851614952087\n",
      "result: 0.9992852210998535\n",
      "result: 0.9993067979812622\n",
      "result: 0.9993070363998413\n",
      "result: 0.9993388056755066\n",
      "result: 0.9993622899055481\n",
      "result: 0.999325156211853\n",
      "result: 0.9993335604667664\n",
      "result: 0.9993436932563782\n",
      "result: 0.9993561506271362\n",
      "result: 0.9993597865104675\n",
      "result: 0.9993679523468018\n",
      "result: 0.9993610382080078\n",
      "result: 0.999377429485321\n",
      "result: 0.9993562698364258\n",
      "result: 0.9993894100189209\n",
      "result: 0.9993798732757568\n",
      "result: 0.999387264251709\n",
      "result: 0.9994073510169983\n",
      "result: 0.9994127154350281\n",
      "result: 0.999409556388855\n",
      "result: 0.9994292259216309\n",
      "result: 0.9994103908538818\n",
      "result: 0.9994389414787292\n",
      "result: 0.9994418025016785\n",
      "result: 0.9994453191757202\n",
      "result: 0.9994688034057617\n",
      "result: 0.9994823336601257\n",
      "result: 0.9994851350784302\n",
      "result: 0.9995036721229553\n",
      "result: 0.9994922280311584\n",
      "result: 0.9994953274726868\n",
      "result: 0.999570906162262\n",
      "result: 0.9995694756507874\n",
      "result: 0.9996144771575928\n",
      "result: 0.9996361136436462\n",
      "result: 0.9996582865715027\n",
      "result: 0.9996984601020813\n",
      "result: 0.9997469186782837\n",
      "result: 0.9997724294662476\n"
     ]
    }
   ],
   "source": [
    "# Load your test data (replace this with your actual data loading code)\n",
    "def load_data(path_dir):\n",
    "    t, signal = mt.battery(path_dir)\n",
    "    tleft = 1 - t / max(t)\n",
    "    t = np.arange(0, len(signal))*100\n",
    "    print(t[-1])\n",
    "    return signal, tleft, t\n",
    "\n",
    "test_data = load_data('data/21-2-25/')\n",
    "test_data, test_param = normalize(test_data)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "print(\"Evaluating on test data...\")\n",
    "eval(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876d2f7-d2bf-433a-a8dc-37872004e7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
